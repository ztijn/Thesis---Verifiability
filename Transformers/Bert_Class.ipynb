{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"Bert_Class.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["#Sentence Classification using BERT"],"metadata":{"id":"EKOTlwcmxmej"}},{"cell_type":"code","source":["import tensorflow as tf\n","# Verifying GPU availability (you have to turn it on in google colab)\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"DEfSbAA4QHas","outputId":"01d1f51e-c604-474c-abd1-28bd22536cb8","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657195798653,"user_tz":-120,"elapsed":3565,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device(\"cuda\")"],"metadata":{"id":"oYsV4H8fCpZ-","trusted":true,"executionInfo":{"status":"ok","timestamp":1657195801982,"user_tz":-120,"elapsed":1169,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"0NmMdkZO8R6q","outputId":"d90ab834-7975-4b83-8982-a34ef3dda945","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657195809140,"user_tz":-120,"elapsed":5816,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"_UkeC7SG2krJ","outputId":"4d864efb-7477-4941-8f65-17e345062ff7","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657195814431,"user_tz":-120,"elapsed":2680,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Loading csv file as df and removing irrelevant / empty (= multiple frames) frames\n","train_df = pd.read_csv('/content/drive/MyDrive/Studie/Thesis/train_set.csv')\n","validation_df = pd.read_csv('/content/drive/MyDrive/Studie/Thesis/val_set.csv')"],"metadata":{"id":"wj2xpqX7exO1","executionInfo":{"status":"ok","timestamp":1657195817138,"user_tz":-120,"elapsed":692,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(train_df.shape)\n","print(validation_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgs15asBe_Fr","executionInfo":{"status":"ok","timestamp":1657195819438,"user_tz":-120,"elapsed":3,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}},"outputId":"f74fe8cc-f1c9-49cf-bc31-b69144c82455"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(7041, 13)\n","(1123, 13)\n"]}]},{"cell_type":"code","source":["from sklearn import preprocessing\n","\n","# Creating list of comments and corresponding labels\n","sentences_train = train_df.sentence.values\n","sentences_val = validation_df.sentence.values\n","\n","# Getting labels           \n","labels_train = train_df.verif.values\n","labels_val = validation_df.verif.values\n","\n","# Getting unique labels \n","un_labels = set()\n","for label in labels_train:\n","  un_labels.add(label)\n","print(len(un_labels), un_labels)\n","# Rewriting labels from str to int so it can be 'understood' by the classifier \n","le = preprocessing.LabelEncoder()\n","le.fit(sorted(un_labels))\n","\n","train_labels = le.transform(labels_train)\n","validation_labels = le.transform(labels_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9Bzi-owfIcJ","executionInfo":{"status":"ok","timestamp":1657195823158,"user_tz":-120,"elapsed":4,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}},"outputId":"83852f08-dcdb-4b37-f1a2-26d1e3ce8936"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["3 {'NonArg', 'Verif', 'UnVerif'}\n"]}]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"metadata":{"id":"Z474sSC6oe7A","trusted":true,"executionInfo":{"status":"ok","timestamp":1657195830923,"user_tz":-120,"elapsed":4354,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def sent_to_id(sentences):\n","  # Tokenize all of the sentences and map the tokens to thier word IDs.\n","  input_ids = []\n","\n","  # For every sentence...\n","  for sent in sentences:\n","      # `encode` will:\n","      #   (1) Tokenize the sentence.\n","      #   (2) Prepend the `[CLS]` token to the start.\n","      #   (3) Append the `[SEP]` token to the end.\n","      #   (4) Map tokens to their IDs.\n","      encoded_sent = tokenizer.encode(\n","                          sent\n","                    )\n","      \n","      # Add the encoded sentence to the list.\n","      input_ids.append(encoded_sent)\n","\n","  # Print sentence 0, now as a list of IDs.\n","  print('Original: ', sentences[0])\n","  print('Token IDs:', input_ids[0])\n","  return(input_ids)"],"metadata":{"id":"2bBdb3pt8LuQ","trusted":true,"executionInfo":{"status":"ok","timestamp":1657195834042,"user_tz":-120,"elapsed":448,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_inputs = sent_to_id(sentences_train)\n","validation_inputs = sent_to_id(sentences_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Yj-NSQ8gGEX","executionInfo":{"status":"ok","timestamp":1657195840990,"user_tz":-120,"elapsed":4801,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}},"outputId":"cbc76839-113f-47b9-89f7-74852127f9d9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  I have so many responses to this, but most of them stem from emotions, so I'm going to put them aside, and just go with two.\n","Token IDs: [101, 1045, 2031, 2061, 2116, 10960, 2000, 2023, 1010, 2021, 2087, 1997, 2068, 7872, 2013, 6699, 1010, 2061, 1045, 1005, 1049, 2183, 2000, 2404, 2068, 4998, 1010, 1998, 2074, 2175, 2007, 2048, 1012, 102]\n","Original:  You don't make any attempt to cite your claims.\n","Token IDs: [101, 2017, 2123, 1005, 1056, 2191, 2151, 3535, 2000, 21893, 2115, 4447, 1012, 102]\n"]}]},{"cell_type":"code","source":["print('Max sentence length(train): ', max([len(sen) for sen in train_inputs]))\n","print('Max sentence length(validation): ', max([len(sen) for sen in validation_inputs]))"],"metadata":{"id":"JhUZO9vc_l6T","outputId":"644a8e87-dfb4-4017-e969-1179917281b6","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657195850370,"user_tz":-120,"elapsed":1069,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Max sentence length(train):  203\n","Max sentence length(validation):  137\n"]}]},{"cell_type":"code","source":["# We will use some utility function from tensorflow(Tensorflow was my first crush)\n","from keras.preprocessing.sequence import pad_sequences\n","\n","MAX_LEN = 305\n","\n","#Padding the input to the max length that is 64\n","train_inputs = pad_sequences(train_inputs, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n","validation_inputs = pad_sequences(validation_inputs, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")"],"metadata":{"id":"Cp9BPRd1tMIo","trusted":true,"executionInfo":{"status":"ok","timestamp":1657195852004,"user_tz":-120,"elapsed":1,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def attentionmasks(input_ids):\n","  # Creating the attention masks\n","  attention_masks = []\n","\n","  # For each sentence...\n","  for sent in input_ids:\n","      \n","      # Create the attention mask.\n","      #   - If a token ID is 0, then it's padding, set the mask to 0.\n","      #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","      att_mask = [int(token_id > 0) for token_id in sent]\n","      \n","      # Store the attention mask for this sentence.\n","      attention_masks.append(att_mask)\n","  return(attention_masks)"],"metadata":{"id":"cDoC24LeEv3N","trusted":true,"executionInfo":{"status":"ok","timestamp":1657195853891,"user_tz":-120,"elapsed":687,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["train_masks = attentionmasks(train_inputs)\n","validation_masks = attentionmasks(validation_inputs)"],"metadata":{"id":"-l_lHhwGiSiX","executionInfo":{"status":"ok","timestamp":1657195857180,"user_tz":-120,"elapsed":1129,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#Converting the input data to the tensor , which can be feeded to the model\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)"],"metadata":{"id":"jw5K2A5Ko1RF","trusted":true,"executionInfo":{"status":"ok","timestamp":1657195859317,"user_tz":-120,"elapsed":432,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#Creating the DataLoader which will help us to load data into the GPU/CPU\n","batch_size = 32\n","\n","# Create the DataLoader for our training set.\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set.\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"],"metadata":{"id":"GEgLpFVlo1Z-","trusted":true,"executionInfo":{"status":"ok","timestamp":1657195861317,"user_tz":-120,"elapsed":2,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["#Loading the pre-trained BERT model from huggingface library\n","\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", \n","    num_labels = 3,   \n","    output_attentions = False, \n","    output_hidden_states = False, )\n","\n","# Teeling the model to run on GPU\n","model.cuda()"],"metadata":{"id":"gFsCTp_mporB","outputId":"9574826d-67e3-40a7-d6ae-df4b39be8a8e","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657195872112,"user_tz":-120,"elapsed":7368,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# AdamW is an optimizer which is a Adam Optimzier with weight-decay-fix\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, \n","                  eps = 1e-8 \n","                )\n"],"metadata":{"id":"GLs72DuMODJO","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657195875395,"user_tz":-120,"elapsed":397,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}},"outputId":"c474bf2d-2b9b-4539-833f-f867fe09639e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 4\n","\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)\n","scheduler"],"metadata":{"id":"-p0upAhhRiIx","outputId":"c764b240-3d6b-4300-c194-20e06b298efd","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657195877592,"user_tz":-120,"elapsed":2,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.optim.lr_scheduler.LambdaLR at 0x7faa2bfc13d0>"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["Define a helper function for calculating accuracy."],"metadata":{"id":"pE5B99H5H2-W"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"9cQNvaZ9bnyy","trusted":true,"executionInfo":{"status":"ok","timestamp":1657195881058,"user_tz":-120,"elapsed":389,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["#Creating the helper function to have a watch on elapsed time\n","\n","import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n"],"metadata":{"id":"gpt6tR83keZD","trusted":true,"executionInfo":{"status":"ok","timestamp":1657195884080,"user_tz":-120,"elapsed":430,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#Let's start the training process\n","\n","import random\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we\n","        # have provided the `labels`.\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        outputs = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels)\n","        \n","        # The call to `model` always returns a tuple, so we need to pull the \n","        # loss value out of the tuple.\n","        loss = outputs[0]\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up validation\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # This will return the logits rather than the loss because we have\n","            # not provided labels.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # Calculate the accuracy for this batch of test sentences.\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        # Accumulate the total accuracy.\n","        eval_accuracy += tmp_eval_accuracy\n","\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","\n","    # Report the final accuracy for this validation run.\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"metadata":{"id":"6J-FYdx6nFE_","outputId":"a8ad3d73-aad5-42a6-cabe-ec4595a83756","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657197393659,"user_tz":-120,"elapsed":1505817,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    221.    Elapsed: 0:01:00.\n","  Batch    80  of    221.    Elapsed: 0:02:02.\n","  Batch   120  of    221.    Elapsed: 0:03:05.\n","  Batch   160  of    221.    Elapsed: 0:04:08.\n","  Batch   200  of    221.    Elapsed: 0:05:13.\n","\n","  Average training loss: 0.64\n","  Training epoch took: 0:05:45\n","\n","Running Validation...\n","  Accuracy: 0.78\n","  Validation took: 0:00:22\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    221.    Elapsed: 0:01:05.\n","  Batch    80  of    221.    Elapsed: 0:02:10.\n","  Batch   120  of    221.    Elapsed: 0:03:15.\n","  Batch   160  of    221.    Elapsed: 0:04:19.\n","  Batch   200  of    221.    Elapsed: 0:05:24.\n","\n","  Average training loss: 0.45\n","  Training epoch took: 0:05:57\n","\n","Running Validation...\n","  Accuracy: 0.78\n","  Validation took: 0:00:22\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    221.    Elapsed: 0:01:05.\n","  Batch    80  of    221.    Elapsed: 0:02:10.\n","  Batch   120  of    221.    Elapsed: 0:03:15.\n","  Batch   160  of    221.    Elapsed: 0:04:19.\n","  Batch   200  of    221.    Elapsed: 0:05:24.\n","\n","  Average training loss: 0.32\n","  Training epoch took: 0:05:57\n","\n","Running Validation...\n","  Accuracy: 0.78\n","  Validation took: 0:00:22\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    221.    Elapsed: 0:01:05.\n","  Batch    80  of    221.    Elapsed: 0:02:10.\n","  Batch   120  of    221.    Elapsed: 0:03:15.\n","  Batch   160  of    221.    Elapsed: 0:04:20.\n","  Batch   200  of    221.    Elapsed: 0:05:25.\n","\n","  Average training loss: 0.23\n","  Training epoch took: 0:05:57\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation took: 0:00:22\n","\n","Training complete!\n"]}]},{"cell_type":"markdown","source":["25 min training time"],"metadata":{"id":"4d2MZ8YtqmvO"}},{"cell_type":"code","source":["print(loss_values) #Having a view of stored loss values in the list"],"metadata":{"id":"btUsZ5vMyjwt","outputId":"6988fbc8-d468-4623-e174-ca448d9518db","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657197471164,"user_tz":-120,"elapsed":444,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.6361248735254167, 0.44543909460171316, 0.3150987568821303, 0.2250876522441795]\n"]}]},{"cell_type":"code","source":["#Loading the test data and applying the same preprocessing techniques which we performed on the train data\n","import pandas as pd\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv('/content/drive/MyDrive/Studie/Thesis/test_set.csv')\n","\n","# Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# Create sentence and label lists\n","sentences = df.sentence.values\n","labels = df.verif.values\n","\n","labels = le.transform(labels)\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                   )\n","    \n","    input_ids.append(encoded_sent)\n","\n","# Pad our input tokens\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n","                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# Create attention masks\n","attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask) \n","\n","# Convert to tensors.\n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(labels)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"metadata":{"id":"mAN0LZBOOPVh","outputId":"c5c33b31-baba-4ae2-9167-719b90fe5a8e","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657197776910,"user_tz":-120,"elapsed":2828,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of test sentences: 1,962\n","\n"]}]},{"cell_type":"code","source":["#Evaluating our model on the test set\n","\n","# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n"],"metadata":{"id":"Hba10sXR7Xi6","outputId":"638a992e-466b-4429-941c-ca09a0b3f699","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657197843565,"user_tz":-120,"elapsed":34899,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting labels for 1,962 test sentences...\n"]}]},{"cell_type":"markdown","source":["We will use Matthews Correlation Coefficient(MCC) to evaluate our model. \n","MCC is used in many areas of Natural Language Processing. Also, it's a great metric to be used for imbalanced dataset\n","\n","Link: https://towardsdatascience.com/the-best-classification-metric-youve-never-heard-of-the-matthews-correlation-coefficient-3bf50a2f3e9a\n"],"metadata":{"id":"-5jscIM8R4Gv"}},{"cell_type":"code","source":["from sklearn.metrics import matthews_corrcoef\n","\n","matthews_set = []\n","\n","# Evaluate each test batch using Matthew's correlation coefficient\n","print('Calculating Matthews Corr. Coef. for each batch...')\n","\n","# For each input batch...\n","for i in range(len(true_labels)):\n","  \n","  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n","  # and one column for \"1\"). Pick the label with the highest value and turn this\n","  # in to a list of 0s and 1s.\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","  \n","  # Calculate and store the coef for this batch.  \n","  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n","  matthews_set.append(matthews)"],"metadata":{"id":"cRaZQ4XC7kLs","outputId":"9fd9e952-5364-4e81-c782-3769152aee20","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657197917125,"user_tz":-120,"elapsed":386,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Calculating Matthews Corr. Coef. for each batch...\n"]}]},{"cell_type":"code","source":["# Combine the predictions for each batch into a single list of 0s and 1s.\n","flat_predictions = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = [item for sublist in true_labels for item in sublist]\n","\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","\n","print('MCC: %.3f' % mcc)"],"metadata":{"id":"oCYZa1lQ8Jn8","outputId":"3eeceb59-090b-4b63-dcb1-c953991d8491","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657197925284,"user_tz":-120,"elapsed":385,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["MCC: 0.568\n"]}]},{"cell_type":"code","source":["#for i in range(len(flat_true_labels)):\n","#  print(flat_true_labels[i], flat_predictions[i])\n","print(len(flat_predictions))\n","unique, counts = np.unique(flat_predictions, return_counts=True)\n","#unique, counts = np.unique(flat_true_labels, return_counts=True)\n","dict(zip(unique, counts))\n","\n","# 0 = NonArg\n","# 1 = UnVerif\n","# 2 = Verif"],"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"aNo9EERdbNgM","executionInfo":{"status":"ok","timestamp":1657197932115,"user_tz":-120,"elapsed":406,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}},"outputId":"0131009d-8ee2-417f-9822-b275a3fa7d99"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["1962\n"]},{"output_type":"execute_result","data":{"text/plain":["{0: 229, 1: 1214, 2: 519}"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["def show_plot(cm, labels):\n","        ax= plt.subplot()\n","        sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n","\n","        # labels, title and ticks\n","        ax.set_xlabel('Predicted Labels');ax.set_ylabel('True Labels'); \n","        ax.set_title('Confusion Matrix'); \n","        ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);\n","        plt.show()"],"metadata":{"id":"cqkYrvmxdzQK","executionInfo":{"status":"ok","timestamp":1657197936797,"user_tz":-120,"elapsed":393,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","accuracy = accuracy_score(flat_true_labels, flat_predictions)\n","print(\"Accuracy: {}\".format(accuracy))\n","\n","macro = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='macro')\n","micro = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')\n","weighted = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='weighted')\n","\n","print(\"micro: precision = {} \\t recall = {} \\t f1 = {}\".format(micro[0], micro[1], micro[2]))\n","print(\"macro: precision = {} \\t recall = {} \\t f1 = {}\".format(macro[0], macro[1], macro[2]))\n","print(\"weighted: precision = {} \\t recall = {} \\t f1 = {}\".format(weighted[0], weighted[1], weighted[2]))\n","\n","per_class = precision_recall_fscore_support(flat_true_labels, flat_predictions, average=None, labels=[0, 1, 2])\n","print(\"Per Class:\")\n","print(\"NonArg: precision = {} \\t recall = {} \\t f1 = {}\".format(per_class[0][0], per_class[1][0], per_class[2][0]))\n","print(\"UnVerif: precision = {} \\t recall = {} \\t f1 = {}\".format(per_class[0][1], per_class[1][1], per_class[2][1]))\n","print(\"Verif: precision = {} \\t recall = {} \\t f1 = {}\".format(per_class[0][2], per_class[1][2], per_class[2][2]))\n","\n","cm = confusion_matrix(flat_true_labels, flat_predictions)\n","show_plot(cm, ['NonArg', 'UnVerif', 'Verif'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434},"id":"4oDkwP-Md16R","executionInfo":{"status":"ok","timestamp":1657197939923,"user_tz":-120,"elapsed":761,"user":{"displayName":"Stijn Wijnen","userId":"04075930552500208092"}},"outputId":"3c2326fc-b1a3-4fe8-c490-8183395fe80f"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7502548419979612\n","micro: precision = 0.7502548419979612 \t recall = 0.7502548419979612 \t f1 = 0.7502548419979611\n","macro: precision = 0.7897824257416697 \t recall = 0.7273449690833248 \t f1 = 0.751629825638758\n","weighted: precision = 0.7543283912050037 \t recall = 0.7502548419979612 \t f1 = 0.7462450024299662\n","Per Class:\n","NonArg: precision = 0.9213973799126638 \t recall = 0.7455830388692579 \t f1 = 0.82421875\n","UnVerif: precision = 0.7331136738056013 \t recall = 0.8549471661863592 \t f1 = 0.7893569844789358\n","Verif: precision = 0.7148362235067437 \t recall = 0.5815047021943573 \t f1 = 0.641313742437338\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}